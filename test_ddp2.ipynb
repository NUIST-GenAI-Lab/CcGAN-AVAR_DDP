{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import os\n",
    "import re\n",
    "import subprocess\n",
    "import sys\n",
    "import tempfile\n",
    "import uuid\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "# 你可以在脚本最上面配置这些常量\n",
    "BASE_OUTPUT_DIR = \"/home/cy/nuist-lab/CcGAN-AVAR/output\"\n",
    "DATA_NAME = \"UTKFace\"\n",
    "IMG_SIZE = 128\n",
    "METRIC_NAME = \"SFID\"  # 或 \"FID\" \"IS\" 等\n",
    "\n",
    "from matplotlib.lines import Line2D  # 顶部建议加一下（虽然这里其实用不到，也无妨）\n",
    "\n",
    "def draw(experiments, title=None, verbose=False):\n",
    "    \"\"\"\n",
    "    experiments: dict\n",
    "        实验名(用于图例) -> (setting_suffix, server_idx)\n",
    "\n",
    "    例如:\n",
    "        experiments = {\n",
    "            \"128 GPUx1\": (\"cy_1_1\", 1),\n",
    "            \"128 GPUx4\": (\"cy_1_0123\", 1),\n",
    "            # \"128 GPUx4 (server83)\": (\"cy_1_0123\", 3),\n",
    "        }\n",
    "    \"\"\"\n",
    "    if not experiments:\n",
    "        print(\"请先在脚本里填写 e_map 再调用 draw。\")\n",
    "        sys.exit()\n",
    "\n",
    "    all_exp_data = {}   # legend_name -> {iter: value}\n",
    "\n",
    "    # ===== 先解析每个实验的 eval 结果 =====\n",
    "    for legend_name, (setting_suffix, server_idx) in experiments.items():\n",
    "        setting_folder = f\"hav_{setting_suffix}\"\n",
    "        result_dir = os.path.join(\n",
    "            BASE_OUTPUT_DIR,\n",
    "            f\"{DATA_NAME}_{IMG_SIZE}\",\n",
    "            setting_folder,\n",
    "            \"results\"\n",
    "        )\n",
    "        summary_path = os.path.join(result_dir, \"all_eval_results.txt\")\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"[Info] 解析实验: {legend_name}\")\n",
    "            print(f\"       setting_suffix = {setting_suffix}, server_idx = {server_idx}\")\n",
    "            print(f\"       summary_path   = {summary_path}\")\n",
    "\n",
    "        iter_to_val = parse_all_eval_results(summary_path, METRIC_NAME, s_idx=server_idx, verbose=verbose)\n",
    "        if not iter_to_val:\n",
    "            print(f\"  -> 没有从 {summary_path} 中解析到任何 {METRIC_NAME} 数据，该实验只在图例中显示，不画点。\")\n",
    "            # 关键：也把它存进去，只是值为空 dict\n",
    "            all_exp_data[legend_name] = {}\n",
    "            continue\n",
    "\n",
    "        all_exp_data[legend_name] = iter_to_val\n",
    "\n",
    "    # 即便所有实验都没数据，all_exp_data 也不为空了，所以这里不用再检查 not all_exp_data\n",
    "\n",
    "    # =====================================================\n",
    "    # 汇总所有 iter 和 所有值，计算 y 轴范围\n",
    "    # =====================================================\n",
    "    all_iters = set()\n",
    "    all_values = []\n",
    "\n",
    "    for _, iter_to_val in all_exp_data.items():\n",
    "        all_iters.update(iter_to_val.keys())\n",
    "        all_values.extend(iter_to_val.values())\n",
    "\n",
    "    all_iters = sorted(all_iters)\n",
    "\n",
    "    if all_values:\n",
    "        y_min = min(all_values)\n",
    "        y_max = max(all_values)\n",
    "        y_range = y_max - y_min if y_max > y_min else 1.0\n",
    "        margin = y_range * 0.1  # 原始设置\n",
    "    else:\n",
    "        # 所有实验都没有任何数值（纯占位图）\n",
    "        y_min, y_max = 0.0, 1.0\n",
    "        y_range = 1.0\n",
    "        margin = 0.1\n",
    "\n",
    "    # =====================================================\n",
    "    # 画图（保持原来的大小/风格）\n",
    "    # =====================================================\n",
    "    plt.figure(figsize=(7, min(2 * len(experiments), 7)))\n",
    "\n",
    "    # 用于之后文本错位计算的缓存\n",
    "    annotations = []  # 每个元素: dict(x=..., y=..., text=..., exp_idx=...)\n",
    "\n",
    "    # 先画曲线 + 记录每个点\n",
    "    for exp_idx, (legend_name, iter_to_val) in enumerate(all_exp_data.items()):\n",
    "        if not iter_to_val:\n",
    "            # 没有任何点的数据：只画一个“空线”，用于 legend\n",
    "            plt.plot(\n",
    "                [], [],\n",
    "                marker=\"o\",\n",
    "                linestyle=\"-\",\n",
    "                linewidth=1.5,\n",
    "                markersize=4,\n",
    "                label=legend_name,\n",
    "            )\n",
    "            continue\n",
    "\n",
    "        iters_sorted = sorted(iter_to_val.keys())\n",
    "        vals_sorted = [iter_to_val[i] for i in iters_sorted]\n",
    "\n",
    "        # 画线\n",
    "        plt.plot(\n",
    "            iters_sorted,\n",
    "            vals_sorted,\n",
    "            marker=\"o\",\n",
    "            linestyle=\"-\",\n",
    "            linewidth=1.5,\n",
    "            markersize=4,\n",
    "            label=legend_name,\n",
    "        )\n",
    "\n",
    "        # 暂时不画文字，只记录下来\n",
    "        for x, y in zip(iters_sorted, vals_sorted):\n",
    "            annotations.append({\n",
    "                \"x\": x,\n",
    "                \"y\": y,\n",
    "                \"text\": f\"{y:.3f}\",\n",
    "                \"exp_idx\": exp_idx,\n",
    "            })\n",
    "\n",
    "    # =====================================================\n",
    "    # 按 x（iteration）聚合点，做“接近 10%”的分组和上下错位\n",
    "    # =====================================================\n",
    "    points_by_x = {}\n",
    "    for i, ann in enumerate(annotations):\n",
    "        x = ann[\"x\"]\n",
    "        points_by_x.setdefault(x, []).append(i)\n",
    "\n",
    "    base_offset_factor = 0.03  # 同一 iter 内的错位幅度\n",
    "\n",
    "    y_text_positions = [None] * len(annotations)\n",
    "\n",
    "    for x, idx_list in points_by_x.items():\n",
    "        if len(idx_list) == 1:\n",
    "            i = idx_list[0]\n",
    "            y0 = annotations[i][\"y\"]\n",
    "            y_text_positions[i] = y0  # 紧贴点\n",
    "            continue\n",
    "\n",
    "        idx_list_sorted = sorted(idx_list, key=lambda i: annotations[i][\"y\"])\n",
    "\n",
    "        # 按“相差 <= 10%”划分子组\n",
    "        groups = []\n",
    "        current_group = [idx_list_sorted[0]]\n",
    "        y_anchor = annotations[idx_list_sorted[0]][\"y\"]\n",
    "\n",
    "        for i in idx_list_sorted[1:]:\n",
    "            y_i = annotations[i][\"y\"]\n",
    "            thr = 0.1 * max(abs(y_anchor), 1e-8)\n",
    "            if abs(y_i - y_anchor) <= thr:\n",
    "                current_group.append(i)\n",
    "            else:\n",
    "                groups.append(current_group)\n",
    "                current_group = [i]\n",
    "                y_anchor = y_i\n",
    "        groups.append(current_group)\n",
    "\n",
    "        # 对每个组做错位\n",
    "        for group in groups:\n",
    "            if len(group) == 1:\n",
    "                j = group[0]\n",
    "                y0 = annotations[j][\"y\"]\n",
    "                y_text_positions[j] = y0 + y_range * 0.02\n",
    "                continue\n",
    "\n",
    "            k = len(group)\n",
    "            rank_center = (k + 1) / 2.0\n",
    "            step = base_offset_factor * y_range\n",
    "\n",
    "            group_sorted = sorted(group, key=lambda j: annotations[j][\"y\"])\n",
    "            for i, j in enumerate(group_sorted):\n",
    "                rank = i + 1\n",
    "                offset = (rank - rank_center) * step\n",
    "                y_text_positions[j] = annotations[j][\"y\"] + offset\n",
    "\n",
    "    # 真正画文字\n",
    "    for ann, y_text in zip(annotations, y_text_positions):\n",
    "        plt.text(\n",
    "            ann[\"x\"],\n",
    "            y_text,\n",
    "            ann[\"text\"],\n",
    "            ha=\"center\",\n",
    "            va=\"bottom\",\n",
    "            fontsize=10,\n",
    "        )\n",
    "\n",
    "    # 轴标签 & 外观\n",
    "    plt.xlabel(\"Iteration\", fontsize=12)\n",
    "    plt.ylabel(METRIC_NAME, fontsize=12)\n",
    "    if title and title.strip() != \"\":\n",
    "        plt.title(title, fontsize=14)\n",
    "\n",
    "    if all_values:\n",
    "        plt.ylim(y_min - margin * 2, y_max + margin)\n",
    "\n",
    "    plt.xticks(all_iters, rotation=45, fontsize=10)\n",
    "    plt.yticks(fontsize=10)\n",
    "    plt.grid(True, linestyle=\"--\", alpha=0.3)\n",
    "    plt.legend(fontsize=10)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # 保存图片\n",
    "    if title and title.strip() != \"\":\n",
    "        safe_title = title.strip()\n",
    "        safe_title = re.sub(r\"\\s+\", \"_\", safe_title)\n",
    "        safe_title = re.sub(r\"[^0-9A-Za-z_-]\", \"_\", safe_title)\n",
    "        safe_title = re.sub(r\"_+\", \"_\", safe_title)\n",
    "        out_name = f\"{safe_title}.png\"\n",
    "    else:\n",
    "        rand_str = uuid.uuid4().hex[:8]\n",
    "        out_name = f\"{METRIC_NAME}_curve_{rand_str}.png\"\n",
    "\n",
    "    out_dir = os.path.join(os.getcwd(), \"temp\")\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    out_path = os.path.join(out_dir, out_name)\n",
    "    plt.savefig(out_path, dpi=200)\n",
    "    print(f\"\\n[完成] 图像已保存为: {out_path}\")\n",
    "\n",
    "    plt.show()\n",
    "def draw1(experiments, title=None, verbose=False):\n",
    "    \"\"\"\n",
    "    experiments: dict\n",
    "        实验名(用于图例) -> (setting_suffix, server_idx)\n",
    "\n",
    "    例如:\n",
    "        experiments = {\n",
    "            \"128 GPUx1\": (\"cy_1_1\", 1),\n",
    "            \"128 GPUx4\": (\"cy_1_0123\", 1),\n",
    "            # \"128 GPUx4 (server83)\": (\"cy_1_0123\", 3),\n",
    "        }\n",
    "    \"\"\"\n",
    "    if not experiments:\n",
    "        print(\"请先在脚本里填写 e_map 再调用 draw。\")\n",
    "        sys.exit()\n",
    "\n",
    "    all_exp_data = {}  # legend_name -> {iter: value}\n",
    "\n",
    "    # ===== 先解析每个实验的 eval 结果 =====\n",
    "    for legend_name, (setting_suffix, server_idx) in experiments.items():\n",
    "        setting_folder = f\"hav_{setting_suffix}\"\n",
    "        result_dir = os.path.join(\n",
    "            BASE_OUTPUT_DIR,\n",
    "            f\"{DATA_NAME}_{IMG_SIZE}\",\n",
    "            setting_folder,\n",
    "            \"results\"\n",
    "        )\n",
    "        summary_path = os.path.join(result_dir, \"all_eval_results.txt\")\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"[Info] 解析实验: {legend_name}\")\n",
    "            print(f\"       setting_suffix = {setting_suffix}, server_idx = {server_idx}\")\n",
    "            print(f\"       summary_path   = {summary_path}\")\n",
    "\n",
    "        iter_to_val = parse_all_eval_results(summary_path, METRIC_NAME, s_idx=server_idx, verbose=verbose)\n",
    "        if not iter_to_val:\n",
    "            print(f\"  -> 没有从 {summary_path} 中解析到任何 {METRIC_NAME} 数据，跳过该实验。\")\n",
    "            continue\n",
    "\n",
    "        all_exp_data[legend_name] = iter_to_val\n",
    "\n",
    "    if not all_exp_data:\n",
    "        print(\"所有实验都没有解析到数据，检查 e_map 配置、路径和 METRIC_NAME 是否正确。\")\n",
    "        sys.exit()\n",
    "\n",
    "    # =====================================================\n",
    "    # 汇总所有 iter 和 所有值，计算 y 轴范围\n",
    "    # =====================================================\n",
    "    all_iters = set()\n",
    "    all_values = []\n",
    "\n",
    "    for _, iter_to_val in all_exp_data.items():\n",
    "        all_iters.update(iter_to_val.keys())\n",
    "        all_values.extend(iter_to_val.values())\n",
    "\n",
    "    all_iters = sorted(all_iters)\n",
    "    y_min = min(all_values)\n",
    "    y_max = max(all_values)\n",
    "    y_range = y_max - y_min if y_max > y_min else 1.0\n",
    "    margin = y_range * 0.1  # 你的原始设置\n",
    "\n",
    "    # =====================================================\n",
    "    # 画图（保持原来的大小/风格）\n",
    "    # =====================================================\n",
    "    plt.figure(figsize=(7, min(2 * len(experiments), 7)))\n",
    "\n",
    "    # 用于之后文本错位计算的缓存\n",
    "    annotations = []  # 每个元素: dict(x=..., y=..., text=..., exp_idx=...)\n",
    "\n",
    "    # 先画曲线 + 记录每个点\n",
    "    for exp_idx, (legend_name, iter_to_val) in enumerate(all_exp_data.items()):\n",
    "        iters_sorted = sorted(iter_to_val.keys())\n",
    "        vals_sorted = [iter_to_val[i] for i in iters_sorted]\n",
    "\n",
    "        # 先画线\n",
    "        plt.plot(\n",
    "            iters_sorted,\n",
    "            vals_sorted,\n",
    "            marker=\"o\",\n",
    "            linestyle=\"-\",\n",
    "            linewidth=1.5,\n",
    "            markersize=4,\n",
    "            label=legend_name,\n",
    "        )\n",
    "\n",
    "        # 暂时不画文字，只记录下来\n",
    "        for x, y in zip(iters_sorted, vals_sorted):\n",
    "            annotations.append({\n",
    "                \"x\": x,\n",
    "                \"y\": y,\n",
    "                \"text\": f\"{y:.3f}\",\n",
    "                \"exp_idx\": exp_idx,\n",
    "            })\n",
    "\n",
    "    # =====================================================\n",
    "    # 按 x（iteration）聚合点，做“接近 10%”的分组和上下错位\n",
    "    # =====================================================\n",
    "    # 构建：某个 iter 上的所有 annotation 索引\n",
    "    points_by_x = {}\n",
    "    for i, ann in enumerate(annotations):\n",
    "        x = ann[\"x\"]\n",
    "        points_by_x.setdefault(x, []).append(i)\n",
    "\n",
    "    # 每组内的上下错位尺度（相对整体 y_range）\n",
    "    base_offset_factor = 0.03  # 想错位更明显就调大一点\n",
    "\n",
    "    # 计算每个 annotation 的文本 y 坐标\n",
    "    y_text_positions = [None] * len(annotations)\n",
    "\n",
    "    for x, idx_list in points_by_x.items():\n",
    "        if len(idx_list) == 1:\n",
    "            # 只有一个点，直接用原逻辑：略微上移\n",
    "            i = idx_list[0]\n",
    "            y0 = annotations[i][\"y\"]\n",
    "            # y_text_positions[i] = y0 + y_range * 0.02\n",
    "            y_text_positions[i] = y0\n",
    "            continue\n",
    "\n",
    "        # 多个点：先按 y 排序\n",
    "        idx_list_sorted = sorted(idx_list, key=lambda i: annotations[i][\"y\"])\n",
    "\n",
    "        # 按“相差 <= 10%”划分子组\n",
    "        groups = []\n",
    "        current_group = [idx_list_sorted[0]]\n",
    "        y_anchor = annotations[idx_list_sorted[0]][\"y\"]\n",
    "\n",
    "        for i in idx_list_sorted[1:]:\n",
    "            y_i = annotations[i][\"y\"]\n",
    "            # 10% 阈值（相对 anchor）\n",
    "            thr = 0.1 * max(abs(y_anchor), 1e-8)\n",
    "            if abs(y_i - y_anchor) <= thr:\n",
    "                current_group.append(i)\n",
    "            else:\n",
    "                groups.append(current_group)\n",
    "                current_group = [i]\n",
    "                y_anchor = y_i\n",
    "        groups.append(current_group)\n",
    "\n",
    "        # 对每个组做错位\n",
    "        for group in groups:\n",
    "            if len(group) == 1:\n",
    "                # 组内只有一个点，不用错位\n",
    "                j = group[0]\n",
    "                y0 = annotations[j][\"y\"]\n",
    "                y_text_positions[j] = y0 + y_range * 0.02\n",
    "                continue\n",
    "\n",
    "            # 组内多点：围绕均值 y_avg 上下排开\n",
    "            k = len(group)\n",
    "            rank_center = (k + 1) / 2.0  # rank从1开始算, 7的话center就是4, 8的话就是4.5\n",
    "            step = base_offset_factor * y_range  # 每个点的间距\n",
    "\n",
    "            # 按 y 排序的顺序，围绕 y_avg 对称错位\n",
    "            group_sorted = sorted(group, key=lambda j: annotations[j][\"y\"])\n",
    "            for i, j in enumerate(group_sorted):\n",
    "                rank = i + 1\n",
    "                offset = (rank - rank_center) * step  # 有正有负\n",
    "                # 根据自身与中心点的排序比例,决定偏移多少\n",
    "                y_text_positions[j] = annotations[j][\"y\"] + offset\n",
    "\n",
    "    # 真正画文字\n",
    "    for ann, y_text in zip(annotations, y_text_positions):\n",
    "        plt.text(\n",
    "            ann[\"x\"],\n",
    "            y_text,\n",
    "            ann[\"text\"],\n",
    "            ha=\"center\",\n",
    "            va=\"bottom\",\n",
    "            fontsize=10,\n",
    "        )\n",
    "\n",
    "    # 轴标签 & 其他外观\n",
    "    plt.xlabel(\"Iteration\", fontsize=12)\n",
    "    plt.ylabel(METRIC_NAME, fontsize=12)\n",
    "    if title and title.strip() != \"\":\n",
    "        plt.title(title, fontsize=14)\n",
    "\n",
    "    # 不额外放大 y 轴，只用你原来的上下 margin 设置\n",
    "    plt.ylim(y_min - margin * 2, y_max + margin)\n",
    "\n",
    "    plt.xticks(all_iters, rotation=45, fontsize=10)\n",
    "    plt.yticks(fontsize=10)\n",
    "    plt.grid(True, linestyle=\"--\", alpha=0.3)\n",
    "    plt.legend(fontsize=10)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # 保存图片\n",
    "    if title and title.strip() != \"\":\n",
    "        safe_title = title.strip()\n",
    "        safe_title = re.sub(r\"\\s+\", \"_\", safe_title)\n",
    "        safe_title = re.sub(r\"[^0-9A-Za-z_-]\", \"_\", safe_title)\n",
    "        safe_title = re.sub(r\"_+\", \"_\", safe_title)\n",
    "        out_name = f\"{safe_title}.png\"\n",
    "    else:\n",
    "        rand_str = uuid.uuid4().hex[:8]\n",
    "        out_name = f\"{METRIC_NAME}_curve_{rand_str}.png\"\n",
    "\n",
    "    out_dir = os.path.join(os.getcwd(), \"temp\")\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    out_path = os.path.join(out_dir, out_name)\n",
    "    plt.savefig(out_path, dpi=200)\n",
    "    print(f\"\\n[完成] 图像已保存为: {out_path}\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def parse_all_eval_results(summary_path, metric_name, s_idx=1, verbose=False):\n",
    "    \"\"\"\n",
    "    从 all_eval_results.txt 中解析出：iter -> metric_value\n",
    "\n",
    "    summary 文件中格式类似：\n",
    "        Checkpoint: ckpt_niter_5000.pth (iter=5000)\n",
    "          SFID: 0.624 (0.165)\n",
    "          LS: 10.124 (7.674)\n",
    "          Diversity: 1.134 (0.093)\n",
    "          FID: 0.624\n",
    "          IS: 2.998 (0.021)\n",
    "\n",
    "    s_idx:\n",
    "        1 -> 本地文件\n",
    "        3 -> 从 cy@192.168.100.83:summary_path 拿\n",
    "        4 -> 从 cy@192.168.100.81:summary_path 拿\n",
    "    \"\"\"\n",
    "\n",
    "    # ========== 根据 s_idx 决定是否走远程 ==========\n",
    "    if s_idx in (3, 4):\n",
    "        # 映射服务器\n",
    "        if s_idx == 3:\n",
    "            host = \"192.168.100.83\"\n",
    "        else:  # s_idx == 4\n",
    "            host = \"192.168.100.81\"\n",
    "\n",
    "        remote_spec = f\"cy@{host}:{summary_path}\"\n",
    "\n",
    "        # 本地缓存目录：/tmp/remote_eval_cache\n",
    "        cache_dir = os.path.join(tempfile.gettempdir(), \"remote_eval_cache\")\n",
    "        os.makedirs(cache_dir, exist_ok=True)\n",
    "\n",
    "        # 为了避免不同服务器间同名文件互相覆盖，前面加 s_idx 前缀\n",
    "        local_fname = f\"s{s_idx}_\" + os.path.basename(summary_path)\n",
    "        local_path = os.path.join(cache_dir, local_fname)\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"[Info] 从远程 {remote_spec} 拷贝到本地缓存: {local_path}\")\n",
    "\n",
    "        try:\n",
    "            # 这里使用 sshpass + scp，如果你还没装：\n",
    "            #   sudo apt-get install sshpass\n",
    "            #\n",
    "            # 警告：密码明文写在脚本里很不安全，仅用于你自己实验环境。\n",
    "            subprocess.run(\n",
    "                [\n",
    "                    \"sshpass\", \"-p\", \"dx666666\",\n",
    "                    \"scp\",\n",
    "                    \"-o\", \"StrictHostKeyChecking=no\",\n",
    "                    remote_spec,\n",
    "                    local_path,\n",
    "                ],\n",
    "                check=True,\n",
    "            )\n",
    "        except FileNotFoundError:\n",
    "            print(\"[错误] sshpass 或 scp 命令不存在，请先安装：sudo apt-get install sshpass openssh-client\")\n",
    "            return {}\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"[错误] scp 远程文件失败：{e}\")\n",
    "            return {}\n",
    "\n",
    "        # 后面统一用本地缓存的路径来解析\n",
    "        summary_path = local_path\n",
    "\n",
    "    # ========== 从（本地）summary_path 解析指标 ==========\n",
    "    if not os.path.isfile(summary_path):\n",
    "        print(f\"[警告] 未找到文件: {summary_path}\")\n",
    "        return {}\n",
    "\n",
    "    iter_to_value = {}\n",
    "    current_iter = None\n",
    "\n",
    "    with open(summary_path, \"r\") as f:\n",
    "        for line in f:\n",
    "            line_stripped = line.strip()\n",
    "\n",
    "            # 匹配：Checkpoint: ckpt_niter_5000.pth (iter=5000)\n",
    "            if line_stripped.startswith(\"Checkpoint:\"):\n",
    "                m_iter = re.search(r\"iter\\s*=\\s*(\\d+)\", line_stripped)\n",
    "                if m_iter:\n",
    "                    current_iter = int(m_iter.group(1))\n",
    "                else:\n",
    "                    current_iter = None\n",
    "                continue\n",
    "\n",
    "            if current_iter is None:\n",
    "                continue\n",
    "\n",
    "            # 匹配指标行，比如：\n",
    "            #   SFID: 0.624 (0.165)\n",
    "            #   FID: 0.624\n",
    "            if line_stripped.startswith(metric_name + \":\"):\n",
    "                m_val = re.search(rf\"{metric_name}:\\s*([0-9eE+\\-\\.]+)\", line_stripped)\n",
    "                if m_val:\n",
    "                    val = float(m_val.group(1))\n",
    "                    iter_to_value[current_iter] = val\n",
    "                continue\n",
    "\n",
    "    return iter_to_value\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "METRIC_NAME = \"SFID\"\n",
    "title = \"linux-1, batch_size = 128\"\n",
    "e_map = {\n",
    "    \"b128 GPUx1\": (\"1_0\", 1),\n",
    "    \"b128 GPUx2 (todo)\": (\"1_01\", 1),\n",
    "    \"b128 GPUx3\": (\"1_123\", 1),\n",
    "    \"b128 GPUx4\": (\"1_0123\", 1),\n",
    "    # \"b128 GPUx1 new code\": (\"cy_1_1\", 1),\n",
    "    # \"b128 GPUx4 new code\": (\"cy_1_0123\", 1),\n",
    "}\n",
    "draw(e_map, title)"
   ],
   "id": "3be90b50b4890b94",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "METRIC_NAME = \"SFID\"\n",
    "title = \"linux-3,4, batch_size = 64\"\n",
    "e_map = {\n",
    "    \"b64 GPUx1 accx2\": (\"3_4_acc2\", 3),\n",
    "    \"b64 GPUx2\": (\"3_01\", 3),\n",
    "    \"b64 GPUx2 sync_bn\": (\"3_23_sync\", 3),\n",
    "    \"b64 GPUx4\": (\"3_0123\", 3),\n",
    "    \"b64 GPUx4 sync_bn (todo)\": (\"3_0123_sync\", 3),\n",
    "\n",
    "    # \"b64 GPUx5\": (\"4_01234\", 4),\n",
    "    \"b64 GPUx5 (todo)\": (\"4_01234\", 4),\n",
    "    \"b64 GPUx5 sync_bn\": (\"4_01234_sync\", 4),\n",
    "\n",
    "    # \"b64 GPUx1 new code\": (\"cy_3_4\", 3),\n",
    "    # \"b64 GPUx1 accx2 new code\": (\"cy_3_2_acc2\", 3),\n",
    "    # \"b64 GPUx1 accx8 new code\": (\"cy_3_3_acc8\", 3),\n",
    "    # \"b64 GPUx2 new code\": (\"cy_3_01\", 3),\n",
    "    # \"b64 GPUx2 sync_bn new code\": (\"cy_3_01_sync\", 3),\n",
    "}\n",
    "draw(e_map, title)"
   ],
   "id": "f8c44544fbfc55a9",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
